# Approaching AGI  
## A personal reflection inspired by Qubic, Neuraxon and AIGARTH

---

## Status

This document is a **personal analytical reflection**.  
It does **not** claim that Artificial General Intelligence (AGI) has been achieved.

Its goal is to explore **how one may realistically approach AGI**,  
based on architectural foundations proposed by Qubic,  
and the research around Neuraxon and AIGARTH.

This is **not** an official Qubic document.

---

## Introduction

For several years, Artificial General Intelligence (AGI) has been widely discussed.  
Often too much.  
And often incorrectly.

Performance is confused with intelligence,  
speed with understanding,  
and data volume with cognitive maturity.

Yet, when observing the real evolution of artificial intelligence systems,  
one fact becomes increasingly clear:  
**scaling models is not enough**.

AGI is not primarily about size.  
It is about **how an intelligence exists, learns, and evolves over time**.

This reflection is built from that premise,  
and from observing the architectural direction taken by **Qubic**,  
particularly through **Neuraxon** and **AIGARTH**.

---

## The Core Limitation of Current AI

Modern AI systems are impressive.  
They speak fluently, reason quickly, and answer almost anything.

However, they share a fundamental weakness:  
**they lack true continuity**.

They learn in phases.  
They forget.  
They repeat the same mistakes.

If an AI is wrong today,  
there is no guarantee it will not be wrong again tomorrow in the same way.

In other words:  
they compute extremely well, but **they do not mature**.

Even an imperfect general intelligence should at least:
- remember its mistakes,
- integrate consequences,
- evolve durably.

---

## Why the Qubic Approach Is Different

Qubic does not take shortcuts.

While it would be easy to integrate a pretrained intelligence and obtain fast, impressive results,  
Qubic made a much harder choice:

**working on foundations, not appearances**.

With **Neuraxon**, the objective is not task optimization,  
but building a **cognitive architecture that exists in time**:
- no constant resets,
- continuous internal activity,
- dynamic memory.

With **AIGARTH**, the ambition is not a specialized AI,  
but a **functionally general intelligence**, developed progressively.

This path is slow.  
Not spectacular at first.  
But structurally different.

---

## Why Qubic Did Not Load a Pretrained Intelligence

Many wonder why Qubic did not simply integrate an existing model.

The reason is simple:  
**pretrained intelligence brings as many limitations as capabilities**.

It introduces:
- frozen biases,
- inherited errors,
- rigid structures.

Most importantly, it prevents something essential:  
**long-term self-correction based on lived experience**.

Qubic chose to start with a more open system,  
capable of transforming itself internally.

Not to move fast early,  
but to go **much further later**.

---

## The Role of Oracles: Reconnecting Intelligence to Reality

An intelligence interacting only through conversation remains abstract.

**Oracles** change this.

They allow the system to:
- observe the world,
- perceive real events,
- detect inconsistencies between beliefs and outcomes.

The intelligence no longer depends only on human prompts.  
It observes, compares, learns.

This is a necessary condition for any credible approach to general intelligence.

---

## Why −1 / 0 / +1 Matters

A subtle but fundamental aspect of Neuraxon is the use of a **trivalent state system (−1 / 0 / +1)**,  
rather than strict binary logic.

Traditional computing relies on yes/no, on/off logic.  
Efficient for calculation, but limited for cognition over time.

In Neuraxon:
- **+1** represents activation,
- **−1** represents active inhibition,
- **0** represents a **functional neutral state**, not absence.

This neutral state allows the system to **withhold immediate responses**  
while maintaining internal coherence.

Instead of forcing premature decisions,  
the system can remain stable, observe changes,  
and let learning emerge progressively.

This is not a moral or conscious choice,  
but a **functional mechanism** for managing uncertainty  
in continuous learning systems.

---

## The Hardest Question: Why Learn?

At the center of AGI research lies a critical question:

*What makes an intelligence want to learn, correct itself, and seek coherence?*

Qubic, Neuraxon, and AIGARTH do **not** claim to have solved this.

But they have done something rare:  
they built an architecture where this question becomes **addressable**.

In a system that:
- exists in time,
- remembers,
- is exposed to reality,

errors can create lasting instability,  
and corrections can restore coherence.

Learning becomes less of an external command  
and more of an internal necessity.

Not human consciousness,  
but a functional step toward durable adaptation.

---

## What Still Remains to Be Built

Being serious about AGI means recognizing what is still missing.

Despite major advances enabled by Qubic, Neuraxon, and AIGARTH,  
some essential components of general intelligence remain open challenges.

### Learning, but Also Wanting to Learn

The architecture enables learning.  
What remains open is a **stable intrinsic reason to learn**.

A truly general intelligence should progress  
not only because it is instructed,  
but because it detects internal inconsistency.

This remains a research frontier.

### Choosing Direction

Today, objectives are still externally defined.  
A closer approximation to AGI would require  
autonomous orientation of learning priorities.

### Stability Over Time

Continuous learning risks drift.  
What remains unresolved is deep stability:  
preserving coherence while evolving.

### Observing, Understanding… Then Acting

Oracles allow observation.  
Action remains limited and must be approached carefully.

---

## Why Everything Depends on the Beginning

Many believe learning large amounts of knowledge is the hardest part.  
In reality, it is the easiest.

Storing information, processing data, adding knowledge:  
machines already do this extremely well and extremely fast.

The real difficulty lies in the foundations:
- continuity,
- memory,
- no reset,
- durable self-correction.

This is where Qubic focused its effort.

Once these foundations exist,  
once the system is truly running,  
learning accelerates naturally.

The machine is fast.  
It does not tire.  

After the hardest phase, progress can become very rapid.

---

## Acknowledgements

This reflection would not exist without the foundational work around Qubic.

Special thanks to **CFB**  
for the long-term vision, architectural coherence,  
and consistency in exploring difficult paths instead of quick wins.

Recognition is also due to **José Sanchez** and **David Vivancos**,  
whose research on **Neuraxon** and **AIGARTH** represents a major contribution.

Their work does not aim to impress.  
It aims to understand.  
Not to promise perfection,  
but to build the conditions for intelligence that can evolve over time.

---

## Personal Conclusion

Achieving perfect AGI may be unrealistic.  
Approaching it honestly is not.

Qubic does not promise the impossible.  
It builds what was missing:  
**time, memory, and real evolution**.

Through **Neuraxon** and **AIGARTH**,  
Qubic chose the hardest path,  
but also the most serious one.

Not a promise.  
A direction.

And in a field as complex as AGI,  
**choosing the right direction is already a major step forward**.
